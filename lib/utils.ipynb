{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b11d478",
   "metadata": {},
   "source": [
    "The goal of this project is to write a data story on philosophy using the dataset for the Philosophy Data Project. Applying data mining, statistical analysis and visualization, students should derive interesting findings in this collection of philosophy texts and write a \"data story\" that can be shared with a general audience.\n",
    "\n",
    "Challenge\n",
    "In this project you will carry out an exploratory data analysis (EDA) of philosophy texts and write a blog on interesting findings from your analysis (i.e., a data story).\n",
    "\n",
    "You are tasked to explore the text corpus using tools from data mining, statistical analysis and visualization, etc, all available in R or Python and write a blog post using R or Python Notebook. Your blog should be in the form of a data story blog on interesting trends and patterns identified by your analysis of these philosophy texts.\n",
    "\n",
    "Even though this is an individual project, you are encouraged to discuss with your classmates and exchange ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8692ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebe99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/philosophy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790af7d",
   "metadata": {},
   "source": [
    "# Describing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9700808e",
   "metadata": {},
   "source": [
    "The dataset contains over 300,000 sentences from over 50 texts spanning 10 major schools of philosophy. The represented schools are: Plato, Aristotle, Rationalism, Empiricism, German Idealism, Communism, Capitalism, Phenomenology, Continental Philosophy, and Analytic Philosophy.\n",
    "\n",
    "Texts were taken either from Project Gutenberg or from my own personal library of pdfs. The dataset is updated periodically as I add new texts to the corpus.\n",
    "\n",
    "The texts were cleaned extensively before being tokenized and organized in the way they're presented here. For information on the cleaning steps, check out the github repo for the initial project, which contains a notebook with all the cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "17e49477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO - charts describing data\n",
    "# titles by author\n",
    "# schools of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "aead9f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360808"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d73e3632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.author.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa841d",
   "metadata": {},
   "source": [
    "# cleaning funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6c88208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_sw(var_in):\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    sw = stopwords.words('english')    \n",
    "    clean_text = [word for word in var_in.split() if word not in sw]\n",
    "    clean_text = ' '.join(clean_text)\n",
    "    return clean_text\n",
    "  \n",
    "def clean_text(var_in):\n",
    "    import re\n",
    "    tmp = re.sub(\"[^A-Za-z]+\", \" \", var_in.lower())\n",
    "    return tmp\n",
    "\n",
    "def stem_fun(var):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    my_stem = PorterStemmer()\n",
    "    tmp = [my_stem.stem(word) for word in var.split()]\n",
    "    tmp = ' '.join(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c21cb",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7378c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rem_sw\"] = data.sentence_lowered.apply(rem_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3575a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rem_sw_stem\"] = data.rem_sw.apply(stem_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a9777ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and save sentiment dictionaries into pos_neg_dict\n",
    "file_names = ['positive-words', 'negative-words']\n",
    "pos_neg_dict = {}\n",
    "for file in file_names:\n",
    "    path = \"/Users/melissa/Desktop/columbia/class/Applied_Data_Science/Fall2021-Project1-melrbischoff/data/{}.txt\".format(\n",
    "        file\n",
    "    )\n",
    "    with open(path, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        contents = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            contents.append(line)\n",
    "    f.close()\n",
    "    pos_neg_dict[file] = contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1da65005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment function from HW 3\n",
    "def gen_senti(arbitrary_text):\n",
    "    '''\n",
    "    Tokenizes arbitrary text and compares each token with the positive and \n",
    "    negative lexicons of each dictionary and outputs the sentiment score, S\n",
    "    '''\n",
    "    import re\n",
    "    arbitrary_text_clean = re.sub(r'[^a-zA-Z ]+', '', arbitrary_text)\n",
    "    arbitrary_text_list = arbitrary_text_clean.split()\n",
    "    \n",
    "    pw = [-1 for word in arbitrary_text_list if word in (pos_neg_dict['negative-words'])]\n",
    "    nw = [1 for word in arbitrary_text_list if word in (pos_neg_dict['positive-words'])]\n",
    "    pc = len(pw)\n",
    "    nc = len(nw)\n",
    "    total = pc + nc\n",
    "    try:\n",
    "        S = (sum(pw) + sum(nw)) / total\n",
    "    except ZeroDivisionError:\n",
    "        S = None\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af2e3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sentiment func to comment body\n",
    "data['simple_senti'] = data.rem_sw_stem.apply(gen_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9c6a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply vader sentiment compound score to comment body\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "vaderSent = SentimentIntensityAnalyzer()\n",
    "data['vader'] = data.rem_sw_stem.apply(\n",
    "    lambda x: vaderSent.polarity_scores(x)['compound']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6640fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_textblob_senti(var_in):\n",
    "    from textblob import TextBlob\n",
    "    blob = TextBlob(var_in)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "data['textblob_senti'] = data.rem_sw_stem.apply(gen_textblob_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c8bcfa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simple_senti</th>\n",
       "      <th>vader</th>\n",
       "      <th>textblob_senti</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>continental</th>\n",
       "      <td>-0.221889</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>0.005911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytic</th>\n",
       "      <td>-0.067521</td>\n",
       "      <td>0.078045</td>\n",
       "      <td>0.026725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenomenology</th>\n",
       "      <td>-0.124603</td>\n",
       "      <td>0.083608</td>\n",
       "      <td>0.024081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communism</th>\n",
       "      <td>0.098497</td>\n",
       "      <td>0.084579</td>\n",
       "      <td>0.032395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminism</th>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.093631</td>\n",
       "      <td>0.050450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               simple_senti     vader  textblob_senti\n",
       "school                                               \n",
       "continental       -0.221889 -0.002555        0.005911\n",
       "analytic          -0.067521  0.078045        0.026725\n",
       "phenomenology     -0.124603  0.083608        0.024081\n",
       "communism          0.098497  0.084579        0.032395\n",
       "feminism           0.005502  0.093631        0.050450"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('school').mean('textblob_senti')[['simple_senti','vader','textblob_senti']].sort_values('vader').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "18be7e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simple_senti</th>\n",
       "      <th>vader</th>\n",
       "      <th>textblob_senti</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Davis</th>\n",
       "      <td>-0.113652</td>\n",
       "      <td>-0.078276</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foucault</th>\n",
       "      <td>-0.210015</td>\n",
       "      <td>-0.020949</td>\n",
       "      <td>-0.017650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Derrida</th>\n",
       "      <td>-0.133301</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deleuze</th>\n",
       "      <td>-0.279859</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.031775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epictetus</th>\n",
       "      <td>-0.063974</td>\n",
       "      <td>0.040315</td>\n",
       "      <td>0.018255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           simple_senti     vader  textblob_senti\n",
       "author                                           \n",
       "Davis         -0.113652 -0.078276        0.023300\n",
       "Foucault      -0.210015 -0.020949       -0.017650\n",
       "Derrida       -0.133301  0.011229        0.011700\n",
       "Deleuze       -0.279859  0.013206        0.031775\n",
       "Epictetus     -0.063974  0.040315        0.018255"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('author').mean('textblob_senti')[['simple_senti','vader','textblob_senti']].sort_values('vader').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a625e6f",
   "metadata": {},
   "source": [
    "# misc funcs from NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eab8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_fun(df_in, path_in, name_in):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    import pandas as pd\n",
    "    my_vec = CountVectorizer()\n",
    "    \n",
    "    my_vec_text = pd.DataFrame(my_vec.fit_transform(df_in).toarray())\n",
    "    my_vec_text.columns = my_vec.get_feature_names()\n",
    "    \n",
    "    write_pickle(path_in + \"output/\", name_in + \".pkl\", my_vec)\n",
    "    return my_vec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57995f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x_in, y_in, split_fraction):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "        x_in,\n",
    "        y_in,\n",
    "        test_size=split_fraction,\n",
    "        random_state=123\n",
    "    )\n",
    "    return X_train_t, X_test_t, y_train_t, y_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f9b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cos_fun(df_in, xform_in, label_in):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import pandas as pd\n",
    "    similarity = pd.DataFrame(cosine_similarity(df_in, xform_in))\n",
    "    similarity.index = label_in\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd466b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>original_publication_date</th>\n",
       "      <th>corpus_edition_date</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title author school  \\\n",
       "0  Plato - Complete Works  Plato  plato   \n",
       "1  Plato - Complete Works  Plato  plato   \n",
       "2  Plato - Complete Works  Plato  plato   \n",
       "3  Plato - Complete Works  Plato  plato   \n",
       "4  Plato - Complete Works  Plato  plato   \n",
       "\n",
       "                                      sentence_spacy  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "   original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "0                       -350                 1997              125   \n",
       "1                       -350                 1997               69   \n",
       "2                       -350                 1997               74   \n",
       "3                       -350                 1997               21   \n",
       "4                       -350                 1997              101   \n",
       "\n",
       "                                    sentence_lowered  \\\n",
       "0   what's new, socrates, to make you leave your ...   \n",
       "1  surely you are not prosecuting anyone before t...   \n",
       "2  the athenians do not call this a prosecution b...   \n",
       "3                              what is this you say?   \n",
       "4  someone must have indicted you, for you are no...   \n",
       "\n",
       "                                       tokenized_txt  \\\n",
       "0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3               ['what', 'is', 'this', 'you', 'say']   \n",
       "4  ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "\n",
       "                                      lemmatized_str  \n",
       "0     what be new , Socrates , to make -PRON- lea...  \n",
       "1   surely -PRON- be not prosecute anyone before ...  \n",
       "2   the Athenians do not call this a prosecution ...  \n",
       "3                          what be this -PRON- say ?  \n",
       "4   someone must have indict -PRON- , for -PRON- ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660ecce",
   "metadata": {},
   "source": [
    "# wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fad391e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0679c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = list(data.author.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6e89a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_works_dict = {a: [] for a in author_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e872055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data[['author','title']].drop_duplicates().reset_index(drop=True).iterrows():\n",
    "    auth = row['author']\n",
    "    titl = row['title']\n",
    "    titl = titl.replace(auth, '')\n",
    "    author_works_dict[auth].append(re.sub('[^A-Za-z0-9]+', ' ', titl.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "442fb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_school_dict = {a: list(data[data.author == a].school.unique())[0].lower() for a in author_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "51a462e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plato'"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_school_dict['Plato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "8c4efb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running author: Plato\n",
      "page title: Plato\n",
      "found page for Plato, it is Plato\n",
      "running author: Aristotle\n",
      "page title: Aristotle\n",
      "found page for Aristotle, it is Aristotle\n",
      "running author: Locke\n",
      "page title: John Locke\n",
      "found page for Locke, it is John Locke\n",
      "running author: Hume\n",
      "page title: David Hume\n",
      "found page for Hume, it is David Hume\n",
      "running author: Berkeley\n",
      "page title: George Berkeley\n",
      "found page for Berkeley, it is George Berkeley\n",
      "running author: Spinoza\n",
      "page title: Baruch Spinoza\n",
      "found page for Spinoza, it is Baruch Spinoza\n",
      "running author: Leibniz\n",
      "page title: Gottfried Wilhelm Leibniz\n",
      "found page for Leibniz, it is Gottfried Wilhelm Leibniz\n",
      "running author: Descartes\n",
      "page title: René Descartes\n",
      "found page for Descartes, it is René Descartes\n",
      "running author: Malebranche\n",
      "cant even find title for Malebranche\n",
      "running author: Russell\n",
      "page title: Russell's teapot\n",
      "CANT FIND page for Russell\n",
      "running author: Moore\n",
      "page title: A. W. Moore (philosopher)\n",
      "found page for Moore, it is A. W. Moore (philosopher)\n",
      "running author: Wittgenstein\n",
      "page title: Ludwig Wittgenstein\n",
      "found page for Wittgenstein, it is Ludwig Wittgenstein\n",
      "running author: Lewis\n",
      "page title: David Lewis (philosopher)\n",
      "found page for Lewis, it is David Lewis (philosopher)\n",
      "running author: Quine\n",
      "cant even find title for Quine\n",
      "running author: Popper\n",
      "cant even find title for Popper\n",
      "running author: Kripke\n",
      "page title: Saul Kripke\n",
      "found page for Kripke, it is Saul Kripke\n",
      "running author: Foucault\n",
      "page title: Michel Foucault\n",
      "found page for Foucault, it is Michel Foucault\n",
      "running author: Derrida\n",
      "page title: Derrida\n",
      "CANT FIND page for Derrida\n",
      "running author: Deleuze\n",
      "page title: Gilles Deleuze\n",
      "found page for Deleuze, it is Gilles Deleuze\n",
      "running author: Merleau-Ponty\n",
      "page title: Maurice Merleau-Ponty\n",
      "found page for Merleau-Ponty, it is Maurice Merleau-Ponty\n",
      "running author: Husserl\n",
      "page title: Edmund Husserl\n",
      "found page for Husserl, it is Edmund Husserl\n",
      "running author: Heidegger\n",
      "page title: Heideggerian terminology\n",
      "found page for Heidegger, it is Heideggerian terminology\n",
      "running author: Kant\n",
      "page title: Immanuel Kant\n",
      "found page for Kant, it is Immanuel Kant\n",
      "running author: Fichte\n",
      "page title: Johann Gottlieb Fichte\n",
      "found page for Fichte, it is Johann Gottlieb Fichte\n",
      "running author: Hegel\n",
      "page title: Georg Wilhelm Friedrich Hegel\n",
      "found page for Hegel, it is Georg Wilhelm Friedrich Hegel\n",
      "running author: Marx\n",
      "page title: Karl Marx\n",
      "found page for Marx, it is Karl Marx\n",
      "running author: Lenin\n",
      "page title: Vladimir Lenin\n",
      "found page for Lenin, it is Vladimir Lenin\n",
      "running author: Smith\n",
      "page title: Adam Smith\n",
      "found page for Smith, it is Adam Smith\n",
      "running author: Ricardo\n",
      "cant even find title for Ricardo\n",
      "running author: Keynes\n",
      "page title: John Maynard Keynes\n",
      "found page for Keynes, it is John Maynard Keynes\n",
      "running author: Epictetus\n",
      "page title: Epictetus\n",
      "found page for Epictetus, it is Epictetus\n",
      "running author: Marcus Aurelius\n",
      "page title: Marcus Aurelius\n",
      "found page for Marcus Aurelius, it is Marcus Aurelius\n",
      "running author: Nietzsche\n",
      "page title: Friedrich Nietzsche\n",
      "found page for Nietzsche, it is Friedrich Nietzsche\n",
      "running author: Wollstonecraft\n",
      "page title: Mary Wollstonecraft\n",
      "found page for Wollstonecraft, it is Mary Wollstonecraft\n",
      "running author: Beauvoir\n",
      "page title: Simone de Beauvoir\n",
      "found page for Beauvoir, it is Simone de Beauvoir\n",
      "running author: Davis\n",
      "page title: Angela Davis\n",
      "found page for Davis, it is Angela Davis\n"
     ]
    }
   ],
   "source": [
    "author_wiki_dict = {}\n",
    "\n",
    "for author in author_list:\n",
    "    print('running author: ' + author)\n",
    "    author_titles = author_works_dict[author]\n",
    "    author_school = author_school_dict[author]\n",
    "    \n",
    "    all_wiki_titles = wikipedia.search(f'philosopher {author} person')\n",
    "    wiki_author_titles = [x for x in all_wiki_titles if author.lower() in x.lower() and 'surname' not in x]\n",
    "    \n",
    "    try:\n",
    "        t = wiki_author_titles[0]\n",
    "        print('page title: ' + t)\n",
    "        content = (wikipedia.WikipediaPage(t).content).lower()\n",
    "            \n",
    "        boolean_ct = []\n",
    "        for title in author_titles:\n",
    "            boolean_ct.append(str(title in content))\n",
    "\n",
    "        if (('True' in boolean_ct) or (author_school in content)):\n",
    "            print(f'found page for {author}, it is {t}')\n",
    "            author_wiki_dict[author] = content\n",
    "        else:\n",
    "            print(f'CANT FIND page for {author}')\n",
    "            author_wiki_dict[author] = 'cant find page'\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f'cant even find title for {author}')\n",
    "        author_wiki_dict[author] = 'cant find title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "f2293363",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_authors = [key for key, value in author_wiki_dict.items() if value == 'cant find page' or value == 'cant find title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "79e3c742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Malebranche', 'Russell', 'Quine', 'Popper', 'Derrida', 'Ricardo']"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "48b36466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running author: Malebranche\n",
      "page title: Nicolas Malebranche\n",
      "found page for Malebranche, it is Nicolas Malebranche\n",
      "running author: Russell\n",
      "page title: Bertrand Russell's philosophical views\n",
      "found page for Russell, it is Bertrand Russell's philosophical views\n",
      "running author: Quine\n",
      "page title: Willard Van Orman Quine\n",
      "found page for Quine, it is Willard Van Orman Quine\n",
      "running author: Popper\n",
      "page title: Karl Popper\n",
      "found page for Popper, it is Karl Popper\n",
      "running author: Derrida\n",
      "page title: Jacques Derrida\n",
      "found page for Derrida, it is Jacques Derrida\n",
      "running author: Ricardo\n",
      "page title: Ricardo Vélez Rodríguez\n",
      "CANT FIND page for Ricardo\n"
     ]
    }
   ],
   "source": [
    "for author in missing_authors:\n",
    "    print('running author: ' + author)\n",
    "    author_school = author_school_dict[author]\n",
    "    author_titles = author_works_dict[author]\n",
    "    \n",
    "    all_titles = wikipedia.search(f'{author} philosopher')\n",
    "    wiki_titles = [x for x in all_titles if author.lower() in x.lower() and 'surname' not in x]\n",
    "    \n",
    "    try:\n",
    "        t = wiki_titles[0]\n",
    "        print('page title: ' + wiki_titles[0])\n",
    "        content = (wikipedia.WikipediaPage(t).content).lower()\n",
    "            \n",
    "        boolean_ct = []\n",
    "        for title in author_titles:\n",
    "            boolean_ct.append(str(title in content))\n",
    "\n",
    "        if ('True' in boolean_ct) or (author_school in content.lower()):\n",
    "            print(f'found page for {author}, it is {wiki_titles[0]}')\n",
    "            author_wiki_dict[author] = content\n",
    "        else:\n",
    "            print(f'CANT FIND page for {author}')\n",
    "            author_wiki_dict[author] = 'cant find page'\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f'cant even find title for {author}')\n",
    "        author_wiki_dict[author] = 'cant find title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "2efbf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_authors_final = [key for key, value in author_wiki_dict.items() if value == 'cant find page' or value == 'cant find title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "4ffb0717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant find wikipedia page for author Ricardo\n"
     ]
    }
   ],
   "source": [
    "if len(missing_authors_final) > 1:\n",
    "    print('cant find wikipedia page for authors: {}'.format(', '.join(missing_authors_final)))\n",
    "if len(missing_authors_final) == 1:\n",
    "    print(f'cant find wikipedia page for author {missing_authors_final[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "59b3ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing authors from dict\n",
    "for author in missing_authors_final:\n",
    "    author_wiki_dict.pop(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2faf76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dict = {a: [] for a in author_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "97d68f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_pronouns = ['she','her','hers']\n",
    "male_pronouns = ['he','him','his']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "21ec317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dict = {}\n",
    "for author, content in author_wiki_dict.items():\n",
    "    female = sum([1 for word in content.split() if word in (female_pronouns)])\n",
    "    male = sum([1 for word in content.split() if word in (male_pronouns)])\n",
    "    if abs(female - male) < 5:\n",
    "        print(f'author {author} has less than 5 diff')\n",
    "        sex_dict[author] = {'female': female,\n",
    "                            'male': male}\n",
    "    elif female > male:\n",
    "        sex_dict[author] = 'female'\n",
    "    elif male > female:\n",
    "        sex_dict[author] = 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "69541066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Plato': 'male',\n",
       " 'Aristotle': 'male',\n",
       " 'Locke': 'male',\n",
       " 'Hume': 'male',\n",
       " 'Berkeley': 'male',\n",
       " 'Spinoza': 'male',\n",
       " 'Leibniz': 'male',\n",
       " 'Descartes': 'male',\n",
       " 'Malebranche': 'male',\n",
       " 'Russell': 'male',\n",
       " 'Moore': 'male',\n",
       " 'Wittgenstein': 'male',\n",
       " 'Lewis': 'male',\n",
       " 'Quine': 'male',\n",
       " 'Popper': 'male',\n",
       " 'Kripke': 'male',\n",
       " 'Foucault': 'male',\n",
       " 'Derrida': 'male',\n",
       " 'Deleuze': 'male',\n",
       " 'Merleau-Ponty': 'male',\n",
       " 'Husserl': 'male',\n",
       " 'Heidegger': 'male',\n",
       " 'Kant': 'male',\n",
       " 'Fichte': 'male',\n",
       " 'Hegel': 'male',\n",
       " 'Marx': 'male',\n",
       " 'Lenin': 'male',\n",
       " 'Smith': 'male',\n",
       " 'Keynes': 'male',\n",
       " 'Epictetus': 'male',\n",
       " 'Marcus Aurelius': 'male',\n",
       " 'Nietzsche': 'male',\n",
       " 'Wollstonecraft': 'female',\n",
       " 'Beauvoir': 'female',\n",
       " 'Davis': 'female'}"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e01f814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "author_dates = data[['author','original_publication_date']].groupby(['author']).max('original_publication_date').join(\n",
    "    data[['author','original_publication_date']].groupby(['author']).min('original_publication_date'),\n",
    "    lsuffix = '_max',\n",
    "    rsuffix = '_min'\n",
    ")\n",
    "\n",
    "author_dates.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9fc38aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lewis - Papers'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.author == 'Lewis'].title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd7da46d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>original_publication_date_max</th>\n",
       "      <th>original_publication_date_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>-320</td>\n",
       "      <td>-320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauvoir</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>1713</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Davis</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deleuze</td>\n",
       "      <td>1972</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Derrida</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Descartes</td>\n",
       "      <td>1641</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Epictetus</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fichte</td>\n",
       "      <td>1798</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Foucault</td>\n",
       "      <td>1966</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hegel</td>\n",
       "      <td>1820</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Heidegger</td>\n",
       "      <td>1950</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hume</td>\n",
       "      <td>1779</td>\n",
       "      <td>1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Husserl</td>\n",
       "      <td>1936</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kant</td>\n",
       "      <td>1790</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Keynes</td>\n",
       "      <td>1936</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kripke</td>\n",
       "      <td>1975</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Leibniz</td>\n",
       "      <td>1710</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lenin</td>\n",
       "      <td>1862</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lewis</td>\n",
       "      <td>1985</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Locke</td>\n",
       "      <td>1689</td>\n",
       "      <td>1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Malebranche</td>\n",
       "      <td>1674</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Marcus Aurelius</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Marx</td>\n",
       "      <td>1883</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Merleau-Ponty</td>\n",
       "      <td>1945</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Moore</td>\n",
       "      <td>1910</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>1888</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Plato</td>\n",
       "      <td>-350</td>\n",
       "      <td>-350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Popper</td>\n",
       "      <td>1959</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Quine</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ricardo</td>\n",
       "      <td>1817</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Russell</td>\n",
       "      <td>1921</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Smith</td>\n",
       "      <td>1776</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Spinoza</td>\n",
       "      <td>1677</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Wittgenstein</td>\n",
       "      <td>1953</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wollstonecraft</td>\n",
       "      <td>1792</td>\n",
       "      <td>1792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author  original_publication_date_max  \\\n",
       "0         Aristotle                           -320   \n",
       "1          Beauvoir                           1949   \n",
       "2          Berkeley                           1713   \n",
       "3             Davis                           1981   \n",
       "4           Deleuze                           1972   \n",
       "5           Derrida                           1967   \n",
       "6         Descartes                           1641   \n",
       "7         Epictetus                            125   \n",
       "8            Fichte                           1798   \n",
       "9          Foucault                           1966   \n",
       "10            Hegel                           1820   \n",
       "11        Heidegger                           1950   \n",
       "12             Hume                           1779   \n",
       "13          Husserl                           1936   \n",
       "14             Kant                           1790   \n",
       "15           Keynes                           1936   \n",
       "16           Kripke                           1975   \n",
       "17          Leibniz                           1710   \n",
       "18            Lenin                           1862   \n",
       "19            Lewis                           1985   \n",
       "20            Locke                           1689   \n",
       "21      Malebranche                           1674   \n",
       "22  Marcus Aurelius                            170   \n",
       "23             Marx                           1883   \n",
       "24    Merleau-Ponty                           1945   \n",
       "25            Moore                           1910   \n",
       "26        Nietzsche                           1888   \n",
       "27            Plato                           -350   \n",
       "28           Popper                           1959   \n",
       "29            Quine                           1950   \n",
       "30          Ricardo                           1817   \n",
       "31          Russell                           1921   \n",
       "32            Smith                           1776   \n",
       "33          Spinoza                           1677   \n",
       "34     Wittgenstein                           1953   \n",
       "35   Wollstonecraft                           1792   \n",
       "\n",
       "    original_publication_date_min  \n",
       "0                            -320  \n",
       "1                            1949  \n",
       "2                            1710  \n",
       "3                            1981  \n",
       "4                            1968  \n",
       "5                            1967  \n",
       "6                            1637  \n",
       "7                             125  \n",
       "8                            1798  \n",
       "9                            1961  \n",
       "10                           1807  \n",
       "11                           1927  \n",
       "12                           1739  \n",
       "13                           1907  \n",
       "14                           1781  \n",
       "15                           1936  \n",
       "16                           1972  \n",
       "17                           1710  \n",
       "18                           1862  \n",
       "19                           1985  \n",
       "20                           1689  \n",
       "21                           1674  \n",
       "22                            170  \n",
       "23                           1848  \n",
       "24                           1945  \n",
       "25                           1910  \n",
       "26                           1886  \n",
       "27                           -350  \n",
       "28                           1959  \n",
       "29                           1950  \n",
       "30                           1817  \n",
       "31                           1912  \n",
       "32                           1776  \n",
       "33                           1677  \n",
       "34                           1921  \n",
       "35                           1792  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from utils.py\n",
    "def tf_idf_fun(df_in, path_in, name_in):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import pandas as pd\n",
    "    my_tf_idf = TfidfVectorizer()\n",
    "    my_tf_idf_text = pd.DataFrame(my_tf_idf.fit_transform(df_in).toarray())\n",
    "    my_tf_idf_text.columns = my_tf_idf.get_feature_names()\n",
    "        \n",
    "    write_pickle(path_in + \"output/\", name_in + \".pkl\", my_tf_idf)\n",
    "    return my_tf_idf_text\n",
    "\n",
    "def vec_fun(df_in, path_in, name_in):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    import pandas as pd\n",
    "    my_vec = CountVectorizer()\n",
    "    \n",
    "    my_vec_text = pd.DataFrame(my_vec.fit_transform(df_in).toarray())\n",
    "    my_vec_text.columns = my_vec.get_feature_names()\n",
    "    \n",
    "    write_pickle(path_in + \"output/\", name_in + \".pkl\", my_vec)\n",
    "    return my_vec_text\n",
    "\n",
    "def tf_idf_fun(df_in, path_in, name_in):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import pandas as pd\n",
    "    my_tf_idf = TfidfVectorizer()\n",
    "    my_tf_idf_text = pd.DataFrame(my_tf_idf.fit_transform(df_in).toarray())\n",
    "    my_tf_idf_text.columns = my_tf_idf.get_feature_names()\n",
    "    return my_tf_idf_text\n",
    "\n",
    "def grid_search_fun(x_in, y_in, params_in, sw):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.svm import SVC\n",
    "    if sw == \"rf\":\n",
    "        my_rf = RandomForestClassifier(random_state=123)\n",
    "    elif sw == \"svm\":\n",
    "        my_rf = SVC(random_state=123)\n",
    "    elif sw == \"nb\":\n",
    "        my_rf = MultinomialNB()\n",
    "    clf = GridSearchCV(my_rf, params_in)\n",
    "    clf.fit(x_in, y_in)\n",
    "    print (\"Best Score:\", clf.best_score_, \"Best Params:\", clf.best_params_)\n",
    "    return clf.best_params_\n",
    "\n",
    "def pca_fun(var, exp_var, path_o):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=exp_var)\n",
    "    pca_data = pca.fit_transform(var)\n",
    "    write_pickle(path_o, \"pca.pkl\", pca)\n",
    "    print(\"# components:\", len(pca.explained_variance_ratio_))\n",
    "    print(\"explained variance:\",sum(pca.explained_variance_ratio_))\n",
    "    return pca_data\n",
    "\n",
    "def perf_metrics(model_in, x_in, y_true):\n",
    "    #How well did this model perform?\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    y_pred = model_in.predict(x_in)\n",
    "    metrics = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted')\n",
    "    return metrics\n",
    "\n",
    "def my_rf(x_in, y_in, out_in, opt_param_in, sw):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    if sw == \"rf\":\n",
    "        my_rf_m = RandomForestClassifier(**opt_param_in)\n",
    "    elif sw == \"svm\":\n",
    "        my_rf_m = SVC(**opt_param_in)\n",
    "    elif sw == \"nb\":\n",
    "        my_rf_m = MultinomialNB(**opt_param_in)\n",
    "    my_rf_m.fit(x_in, y_in) #model is trained\n",
    "    write_pickle(out_in, \"rf.pkl\", my_rf_m)\n",
    "    return my_rf_m\n",
    "\n",
    "def split_data(x_in, y_in, split_fraction):\n",
    "    # training test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "        x_in, y_in, test_size=split_fraction, random_state=42)\n",
    "    return X_train_t, X_test_t, y_train_t, y_test_t\n",
    "\n",
    "def my_cos_fun(df_in, xform_in, label_in):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import pandas as pd\n",
    "    similarity = pd.DataFrame(cosine_similarity(df_in, xform_in))\n",
    "    similarity.index = label_in\n",
    "    return similarity\n",
    "\n",
    "def my_pca(df_in, o_path):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=0.95)\n",
    "    my_pca_txt = pca.fit_transform(df_in)\n",
    "    write_pickle(o_path, \"pca.pkl\", pca)\n",
    "    return my_pca_txt\n",
    "\n",
    "def score_text(model_in, var_in):\n",
    "    import numpy as np\n",
    "    the_pred = model_in.predict(var_in)\n",
    "    probs = model_in.predict_proba(var_in)\n",
    "    print (\"Predicted text:\", the_pred[0], \"With probability of:\",\n",
    "           str(round(np.max(probs)*100, 2)) + \"%\")\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
